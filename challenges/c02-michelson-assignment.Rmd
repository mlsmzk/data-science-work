---
title: "Michelson Speed-of-light Measurements"
author: "Miles Mezaki"
date: 2020-
output:
  github_document:
    toc: true
prerequisites:
  - e-data02-derive
editor_options: 
  markdown: 
    wrap: 72
---

*Purpose*: When studying physical problems, there is an important
distinction between *error* and *uncertainty*. The primary purpose of
this challenge is to dip our toes into these factors by analyzing a real
dataset.

*Reading*: [Experimental Determination of the Velocity of
Light](https://play.google.com/books/reader?id=343nAAAAMAAJ&hl=en&pg=GBS.PA115)
(Optional)

<!-- include-rubric -->

# Grading Rubric

<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics
define how you will be graded, both on an individual and team basis.

## Individual

<!-- ------------------------- -->

| Category    | Needs Improvement                                                                                                | Satisfactory                                                                                                               |
|------------------|-----------------------------|-------------------------|
| Effort      | Some task **q**'s left unattempted                                                                               | All task **q**'s attempted                                                                                                 |
| Observed    | Did not document observations, or observations incorrect                                                         | Documented correct observations based on analysis                                                                          |
| Supported   | Some observations not clearly supported by analysis                                                              | All observations clearly supported by analysis (table, graph, etc.)                                                        |
| Assessed    | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support      |
| Specified   | Uses the phrase "more data are necessary" without clarification                                                  | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability                                 | Code sufficiently close to the [style guide](https://style.tidyverse.org/)                                                 |

## Due Date

<!-- ------------------------- -->

All the deliverables stated in the rubrics above are due **at midnight**
before the day of the class discussion of the challenge. See the
[Syllabus](https://docs.google.com/document/d/1qeP6DUS8Djq_A0HMllMqsSqX3a9dbcx1/edit?usp=sharing&ouid=110386251748498665069&rtpof=true&sd=true)
for more information.

```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(googlesheets4)

url <- "https://docs.google.com/spreadsheets/d/1av_SXn4j0-4Rk0mQFik3LLr-uf0YdA06i3ugE6n-Zdo/edit?usp=sharing"

# Parameters
LIGHTSPEED_VACUUM    <- 299792.458 # Exact speed of light in a vacuum (km / s)
LIGHTSPEED_MICHELSON <- 299944.00  # Michelson's speed estimate (km / s)
LIGHTSPEED_PM        <- 51         # Michelson error estimate (km / s)
```

*Background*: In 1879 Albert Michelson led an experimental campaign to
measure the speed of light. His approach was a development upon the
method of Foucault[3], and resulted in a new estimate of
$v_0 = 299944 \pm 51$ kilometers per second (in a vacuum). This is very
close to the modern *exact* value of `r LIGHTSPEED_VACUUM`. In this
challenge, you will analyze Michelson's original data, and explore some
of the factors associated with his experiment.

I've already copied Michelson's data from his 1880 publication; the code
chunk below will load these data from a public googlesheet.

*Aside*: The speed of light is *exact* (there is **zero error** in the
value `LIGHTSPEED_VACUUM`) because the meter is actually
[*defined*](https://en.wikipedia.org/wiki/Metre#Speed_of_light_definition)
in terms of the speed of light!

```{r read-sheet}
## Note: No need to edit this chunk!
gs4_deauth()
ss <- gs4_get(url)
df_michelson <-
  read_sheet(ss) %>%
  select(Date, Distinctness, Temp, Velocity) %>%
  mutate(Distinctness = as_factor(Distinctness))

df_michelson %>% glimpse
```

*Data dictionary*:

-   `Date`: Date of measurement
-   `Distinctness`: Distinctness of measured images: 3 = good, 2 = fair,
    1 = poor
-   `Temp`: Ambient temperature (Fahrenheit)
-   `Velocity`: Measured speed of light (km / s)

### **q1** Re-create the following table (from Michelson (1880), pg. 139) using `df_michelson` and `dplyr`. Note that your values *will not* match those of Michelson *exactly*; why might this be?

| Distinctness | n   | MeanVelocity |
|--------------|-----|--------------|
| 3            | 46  | 299860       |
| 2            | 39  | 299860       |
| 1            | 15  | 299810       |

```{r q1-task}
## TODO: Compute summaries
df_q1 <- df_michelson
df_michelson %>%
  group_by(Distinctness) %>%
    summarize(n = n(), MeanVelocity = mean(Velocity)) %>%
      arrange(desc(n))
```

**Observations**: - While distinctness and n naturally match Michelson's
data, the mean velocity that I compute is slightly different. This may
be attributed to a difference in technology; whether it be the measuring
equipment used to capture the velocities, or the computers used to
calculate the mean velocities.

The `Velocity` values in the dataset are the speed of light *in air*;
Michelson introduced a couple of adjustments to estimate the speed of
light in a vacuum. In total, he added $+92$ km/s to his mean estimate
for `VelocityVacuum` (from Michelson (1880), pg. 141). While the
following isn't fully rigorous ($+92$ km/s is based on the mean
temperature), we'll simply apply this correction to all the observations
in the dataset.

### **q2** Create a new variable `VelocityVacuum` with the $+92$ km/s adjustment to `Velocity`. Assign this new dataframe to `df_q2`.

```{r q2-task}
## TODO: Adjust the data, assign to df_q2
df_q2 <- df_michelson %>%
  mutate(VelocityVacuum = Velocity + 92)

df_q2
```

As part of his study, Michelson assessed the various potential sources
of error, and provided his best-guess for the error in his
speed-of-light estimate. These values are provided in
`LIGHTSPEED_MICHELSON`---his nominal estimate---and
`LIGHTSPEED_PM`---plus/minus bounds on his estimate. Put differently,
Michelson believed the true value of the speed-of-light probably lay
between `LIGHTSPEED_MICHELSON - LIGHTSPEED_PM` and
`LIGHTSPEED_MICHELSON + LIGHTSPEED_PM`.

Let's introduce some terminology:[2]

-   **Error** is the difference between a true value and an estimate of
    that value; for instance `LIGHTSPEED_VACUUM - LIGHTSPEED_MICHELSON`.
-   **Uncertainty** is an analyst's *assessment* of the error.

Since a "true" value is often not known in practice, one generally does
not know the error. The best they can do is quantify their degree of
uncertainty. We will learn some means of quantifying uncertainty in this
class, but for many real problems uncertainty includes some amount of
human judgment.[2]

### **q3** Compare Michelson's speed of light estimate against the modern speed of light value. Is Michelson's estimate of the error (his uncertainty) greater or less than the true error?

```{r q3-task}
## TODO: Compare Michelson's estimate and error against the true value
## Your code here!
ERROR <- LIGHTSPEED_VACUUM - LIGHTSPEED_MICHELSON
ERROR

UNCERTAINTY <- LIGHTSPEED_PM
UNCERTAINTY
```

**Observations**:

\- Is Michelson's estimate of the error (his uncertainty) greater or
less than the true error? - The estimate of his error is less than the
true error.

\- Make a quantitative comparison between Michelson's uncertainty and
his error. - The estimate of his error (his uncertainty) is +/- 51 km/s.
Whereas the actual speed of light is 151.542 km/s less than he
predicted. Thus he was more certain of his results than he should have
been to be factually accurate, being off by about 100 km/s at best,
since LIGHTSPEED_VACUUM is precisely the speed of light.

The following plot shows all of Michelson's data as a [control
chart](https://en.wikipedia.org/wiki/Control_chart); this sort of plot
is common in manufacturing, where it is used to help determine if a
manufacturing process is under [statistical
control](https://en.wikipedia.org/wiki/Statistical_process_control).
Each dot is one of Michelson's measurements, and the grey line connects
the mean taken for each day. The same plot also shows simulated data
using a probability model. We'll get into statistics later in the
course; for now, let's focus on understanding what real and simulated
data tend to look like.

### **q4** Inspect the following plot with the `Real` Michelson data and `Simulated` data from a probability model. Document the similarities and differences between the data under *observe* below.

```{r q4-cf-real-simulated}
## Note: No need to edit this chunk!
## Calibrate simulated data
v_mean <-
  df_q2 %>%
  summarize(m = mean(VelocityVacuum)) %>%
  pull(m)
v_sd <-
  df_q2 %>%
  summarize(s = sd(VelocityVacuum)) %>%
  pull(s)

## Visualize
set.seed(101)
df_q2 %>%
  mutate(Simulated = rnorm(n(), mean = v_mean, sd = v_sd)) %>%
  rename(Real = VelocityVacuum) %>%
  pivot_longer(
    cols = c(Simulated, Real),
    names_to = "source",
    values_to = "velocity"
  ) %>%

  ggplot(aes(Date, velocity)) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON,
    linetype = "dotted"
  ) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON - LIGHTSPEED_PM,
    linetype = "dashed"
  ) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON + LIGHTSPEED_PM,
    linetype = "dashed"
  ) +

  geom_line(
    data = . %>%
      group_by(Date, source) %>%
      summarize(velocity_mean = mean(velocity)),
    mapping = aes(y = velocity_mean),
    color = "grey50"
  ) +
  geom_point(
    mapping = aes(y = velocity),
    size = 0.8
  ) +

  facet_grid(source~.) +
  theme_minimal() +
  labs(
    x = "Date of Measurement (1879)",
    y = "Velocity (in Vacuum)"
  )
```

**Observations**:

Similarities - The means have the same general trend and are not
significantly far from each other, in most cases. Both graphs display
very high measurements and very low measurements, but the means almost
all fall into the interval between 299900 and 300000 km/s.

Differences - The behavior of the probabilistic model tends to peak at
the end, whereas the real results peak toward the beginning. The number
of data points per day tend to differ significantly from real to
probabilistic model, which is an interesting view of the probability
model, which evidently "predicts" a certain number of data points taken
per day. The probabilistic model of course tends to be lower, which is
slightly closer to the real value of the speed of light.

### **q5** You have access to a few other variables. Construct a few visualizations of `VelocityVacuum` against these other factors. Are there other patterns in the data that might help explain the difference between Michelson's estimate and `LIGHTSPEED_VACUUM`?

```{r}
df_q2 %>%
##  group_by(Date) %>%
##  summarize(temp = Temp, VelocityVacuum = VelocityVacuum) %>%
  
  ggplot() +
  geom_histogram(mapping = aes(x = VelocityVacuum, fill = Distinctness), boundary = LIGHTSPEED_VACUUM)

df_q2 %>%
  ggplot() +
  geom_point(mapping = aes(x = Date, y = VelocityVacuum, color = Temp))

df_q2 %>%
  ggplot() +
  geom_point(mapping = aes(x = Date, y = VelocityVacuum, color = Distinctness))

df_q2 %>%  
ggplot() +
  geom_density(mapping = aes(x = VelocityVacuum, color = Distinctness))


```

**Observations**:

-   Graph 1
    -   Significantly more measurements with distinctness 2 or 3 were
        measured than distinctness 1. If distinctness has an effect on
        the measured velocity, it could explain why the error was so
        great.
-   Graph 2
    -   There was a different number of measurements taken on each day.
        I'm not a physicist, but I would want to collect the same number
        of samples every time that I repeat my experiment to control for
        external conditions influencing my data. This scatterplot also
        seemingly indicates little effect of temperature on the "vacuum"
        velocity, but lower temperatures seem to have slightly lower
        speeds on average.
-   Graph 3
    -   Again we can see the scarcity of distinctness 1 results, but
        their prevalence in one segment of time may indicate a problem
        with the measuring apparatus; why aren't there measurements of
        distinctness 1 outside that timeframe? It seems that
        distinctness 1 averages the lowest temperature, with
        distinctness 3 second lowest, then distinctness 2. Since the
        speed of light in actuality is 151 km/s slower, I wonder if this
        lack of category biased the data.
-   Graph 4
    -   Since the density graph normalizes based on the number of
        samples, I thought it might be a good idea for the distinctness
        categories. Both distinctness 2 and 3 have a slight right skew
        to their curves, whereas distinctness 1 has a slight left skew.
        Looking at the other visualizations, this would be expected.
        Unfortunately this seemingly does not illustrate new information
        about the data.

## Bibliography

-   [1] Michelson, [Experimental Determination of the Velocity of
    Light](https://play.google.com/books/reader?id=343nAAAAMAAJ&hl=en&pg=GBS.PA115)
    (1880)
-   [2] Henrion and Fischhoff, [Assessing Uncertainty in Physical
    Constants](https://www.cmu.edu/epp/people/faculty/research/Fischoff-Henrion-Assessing%20uncertainty%20in%20physical%20constants.pdf)
    (1986)
-   [3] BYU video about a [Fizeau-Foucault
    apparatus](https://www.youtube.com/watch?v=Ik5ORaaeaME), similar to
    what Michelson used.
